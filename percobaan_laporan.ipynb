{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Percobaan Laporan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah kumpulan kode yang kami gunakan untuk melakukan berbagai percobaan yang dibutuhkan pada laporan.\n",
    "\n",
    "Semoga membantu bagi kakak untuk memahami cara menggunakan model kami demi menjalankan test case! :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import segala file dan library yang diperlukan\n",
    "import numpy as np\n",
    "\n",
    "from src.tensor import Tensor\n",
    "from src.activation_function import Linear, ReLU, Sigmoid, Softmax\n",
    "from src.loss_function import MeanSquaredError\n",
    "from src.layer import Dense\n",
    "from src.model import FFNN\n",
    "from src.weight_initializer import GlorotUniformInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X = X / 255.0   # normalisasi\n",
    "\n",
    "y = y.astype(int)\n",
    "num_classes = np.max(y) + 1\n",
    "y = np.eye(num_classes)[y]    # one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mempercepat proses training dan prediksi, kami hanya mengambil:\n",
    "- 500 data awal training set (400 training data + 100 validation data)\n",
    "- 200 data awal test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (400, 784), (400, 10)\n",
      "Validation set: (100, 784), (100, 10)\n",
      "Test set: (200, 784), (200, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = X_train[:400], y_train[:400]\n",
    "X_val, y_val = X_val[:100], y_val[:100]\n",
    "X_test, y_test = X_test[:200], y_test[:200]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pengaruh Depth dan Width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2145\n",
      "Validation Loss: 0.1695\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1540\n",
      "Validation Loss: 0.1260\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.0949\n",
      "Validation Loss: 0.1350\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.0751\n",
      "Validation Loss: 0.0946\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0514\n",
      "Validation Loss: 0.1251\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0377\n",
      "Validation Loss: 0.0757\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0238\n",
      "Validation Loss: 0.0748\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0186\n",
      "Validation Loss: 0.0799\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0140\n",
      "Validation Loss: 0.0809\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0108\n",
      "Validation Loss: 0.0836\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0104\n",
      "Validation Loss: 0.0849\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0093\n",
      "Validation Loss: 0.0936\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0048\n",
      "Validation Loss: 0.0932\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0047\n",
      "Validation Loss: 0.0876\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0037\n",
      "Validation Loss: 0.0942\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0028\n",
      "Validation Loss: 0.0970\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0022\n",
      "Validation Loss: 0.0980\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0018\n",
      "Validation Loss: 0.0999\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0014\n",
      "Validation Loss: 0.1018\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0012\n",
      "Validation Loss: 0.1031\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0799, Accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.1973\n",
      "Validation Loss: 0.1306\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.0956\n",
      "Validation Loss: 0.0939\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.0558\n",
      "Validation Loss: 0.0803\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.0381\n",
      "Validation Loss: 0.0679\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0277\n",
      "Validation Loss: 0.0653\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0209\n",
      "Validation Loss: 0.0642\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0159\n",
      "Validation Loss: 0.0638\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0122\n",
      "Validation Loss: 0.0638\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0097\n",
      "Validation Loss: 0.0641\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0078\n",
      "Validation Loss: 0.0644\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0063\n",
      "Validation Loss: 0.0644\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0051\n",
      "Validation Loss: 0.0645\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0043\n",
      "Validation Loss: 0.0648\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0037\n",
      "Validation Loss: 0.0651\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0032\n",
      "Validation Loss: 0.0654\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0029\n",
      "Validation Loss: 0.0658\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0026\n",
      "Validation Loss: 0.0661\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0023\n",
      "Validation Loss: 0.0664\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0021\n",
      "Validation Loss: 0.0666\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0020\n",
      "Validation Loss: 0.0669\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0588, Accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2281\n",
      "Validation Loss: 0.1991\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.2159\n",
      "Validation Loss: 0.2812\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.3626\n",
      "Validation Loss: 0.3114\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.4109\n",
      "Validation Loss: 0.6359\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 1.0130\n",
      "Validation Loss: 1.5166\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 1.4139\n",
      "Validation Loss: 1.2205\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 1.6132\n",
      "Validation Loss: 1.9687\n",
      "--------------------\n",
      "[#######-------------] 35.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\src\\tensor.py:152: RuntimeWarning: overflow encountered in multiply\n",
      "  res = Tensor(self.data * other.data, [self, other], \"*\")\n",
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\src\\activation_function.py:63: RuntimeWarning: invalid value encountered in subtract\n",
      "  x_shifted = x - np.max(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: nan, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2341\n",
      "Validation Loss: 0.2160\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1951\n",
      "Validation Loss: 0.1557\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.2610\n",
      "Validation Loss: 0.4143\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.6481\n",
      "Validation Loss: 1.1345\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.7866\n",
      "Validation Loss: 0.9210\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.8926\n",
      "Validation Loss: 0.8114\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.5865\n",
      "Validation Loss: 0.6944\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.9088\n",
      "Validation Loss: 1.1109\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.6396\n",
      "Validation Loss: 0.6819\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.5902\n",
      "Validation Loss: 0.6146\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.3439\n",
      "Validation Loss: 0.4984\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.3703\n",
      "Validation Loss: 0.6151\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.3684\n",
      "Validation Loss: 0.6347\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.3115\n",
      "Validation Loss: 0.4660\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.1285\n",
      "Validation Loss: 0.4187\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.1972\n",
      "Validation Loss: 0.6289\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.1453\n",
      "Validation Loss: 0.4849\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.1308\n",
      "Validation Loss: 0.4673\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.1916\n",
      "Validation Loss: 0.4237\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.1989\n",
      "Validation Loss: 0.3137\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=64, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4697, Accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2265\n",
      "Validation Loss: 0.2656\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1850\n",
      "Validation Loss: 0.2204\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.1394\n",
      "Validation Loss: 0.2125\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.1338\n",
      "Validation Loss: 0.1882\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0887\n",
      "Validation Loss: 0.1180\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0533\n",
      "Validation Loss: 0.0983\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0410\n",
      "Validation Loss: 0.1136\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0310\n",
      "Validation Loss: 0.1042\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0246\n",
      "Validation Loss: 0.1072\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0196\n",
      "Validation Loss: 0.1017\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0258\n",
      "Validation Loss: 0.1021\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0198\n",
      "Validation Loss: 0.1118\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0152\n",
      "Validation Loss: 0.1075\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0099\n",
      "Validation Loss: 0.1369\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0059\n",
      "Validation Loss: 0.1229\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0030\n",
      "Validation Loss: 0.1191\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0022\n",
      "Validation Loss: 0.1153\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0019\n",
      "Validation Loss: 0.1181\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0015\n",
      "Validation Loss: 0.1169\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0010\n",
      "Validation Loss: 0.1180\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=128, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0978, Accuracy: 0.8350\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2178\n",
      "Validation Loss: 0.2239\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1696\n",
      "Validation Loss: 0.1680\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.1162\n",
      "Validation Loss: 0.1211\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.0942\n",
      "Validation Loss: 0.1486\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0689\n",
      "Validation Loss: 0.1900\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0491\n",
      "Validation Loss: 0.1069\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0351\n",
      "Validation Loss: 0.0988\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0221\n",
      "Validation Loss: 0.0923\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0171\n",
      "Validation Loss: 0.1051\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0155\n",
      "Validation Loss: 0.1026\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0106\n",
      "Validation Loss: 0.1247\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0090\n",
      "Validation Loss: 0.1003\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0085\n",
      "Validation Loss: 0.1000\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0065\n",
      "Validation Loss: 0.1010\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0042\n",
      "Validation Loss: 0.0982\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0030\n",
      "Validation Loss: 0.1010\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0021\n",
      "Validation Loss: 0.1032\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0015\n",
      "Validation Loss: 0.1031\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0012\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0010\n",
      "Validation Loss: 0.1046\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0844, Accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pengaruh Fungsi Aktivasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.5568\n",
      "Validation Loss: 0.4145\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.3834\n",
      "Validation Loss: 0.4145\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.3834\n",
      "Validation Loss: 0.4145\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.2904\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.1813\n",
      "Validation Loss: 0.1865\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"relu\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2383, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 1.9303\n",
      "Validation Loss: 2.0723\n",
      "--------------------\n",
      "[#-------------------] 5.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\src\\tensor.py:152: RuntimeWarning: overflow encountered in multiply\n",
      "  res = Tensor(self.data * other.data, [self, other], \"*\")\n",
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: nan\n",
      "Validation Loss: nan\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"linear\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"linear\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: nan, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\src\\activation_function.py:59: RuntimeWarning: overflow encountered in exp\n",
      "  return np.power((2 / (np.exp(x) - np.exp(-x))), 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.6616\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.6217\n",
      "Validation Loss: 0.3730\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5803, Accuracy: 0.1050\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.5473\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.4248\n",
      "Validation Loss: 0.3523\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"gelu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"gelu\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3834, Accuracy: 0.0950\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Sidiq\\Documents\\uni\\smt 6\\ml\\tugas\\IF3270_FFNN\\src\\activation_function.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.1837\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.1502\n",
      "Validation Loss: 0.1036\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"silu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"silu\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1554, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pengaruh Inisialisasi Bobot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2303\n",
      "Validation Loss: 0.2287\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.2297\n",
      "Validation Loss: 0.2279\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.2295\n",
      "Validation Loss: 0.2274\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2271\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2269\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2268\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2267\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2267\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"zeros\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"zeros\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 1.2609\n",
      "Validation Loss: 0.8643\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.5566\n",
      "Validation Loss: 0.5830\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.4775\n",
      "Validation Loss: 0.6569\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.3736\n",
      "Validation Loss: 0.5822\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.3405\n",
      "Validation Loss: 0.4967\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.1488\n",
      "Validation Loss: 0.5568\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0978\n",
      "Validation Loss: 0.4939\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0655\n",
      "Validation Loss: 0.4840\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0457\n",
      "Validation Loss: 0.4357\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0195\n",
      "Validation Loss: 0.4578\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0120\n",
      "Validation Loss: 0.4124\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0215\n",
      "Validation Loss: 0.3980\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0104\n",
      "Validation Loss: 0.4131\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0017\n",
      "Validation Loss: 0.4504\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0033\n",
      "Validation Loss: 0.4548\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0000\n",
      "Validation Loss: 0.4547\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0000\n",
      "Validation Loss: 0.4547\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0000\n",
      "Validation Loss: 0.4547\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0000\n",
      "Validation Loss: 0.4547\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0000\n",
      "Validation Loss: 0.4547\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"random_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"random_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3737, Accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2412\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.2441\n",
      "Validation Loss: 0.2328\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.2364\n",
      "Validation Loss: 0.2295\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.2328\n",
      "Validation Loss: 0.2280\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.2310\n",
      "Validation Loss: 0.2273\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.2301\n",
      "Validation Loss: 0.2269\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.2297\n",
      "Validation Loss: 0.2268\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.2295\n",
      "Validation Loss: 0.2267\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.2294\n",
      "Validation Loss: 0.2267\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.2293\n",
      "Validation Loss: 0.2266\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"random_normal\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"random_normal\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2311, Accuracy: 0.1100\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.1950\n",
      "Validation Loss: 0.1611\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.0980\n",
      "Validation Loss: 0.0953\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.0522\n",
      "Validation Loss: 0.0792\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.0383\n",
      "Validation Loss: 0.0725\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0294\n",
      "Validation Loss: 0.0710\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0230\n",
      "Validation Loss: 0.0699\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0182\n",
      "Validation Loss: 0.0695\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0144\n",
      "Validation Loss: 0.0699\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0117\n",
      "Validation Loss: 0.0702\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0093\n",
      "Validation Loss: 0.0704\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0073\n",
      "Validation Loss: 0.0710\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0059\n",
      "Validation Loss: 0.0713\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0048\n",
      "Validation Loss: 0.0718\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0041\n",
      "Validation Loss: 0.0720\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0036\n",
      "Validation Loss: 0.0723\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0032\n",
      "Validation Loss: 0.0727\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0028\n",
      "Validation Loss: 0.0730\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0025\n",
      "Validation Loss: 0.0733\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0023\n",
      "Validation Loss: 0.0736\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0021\n",
      "Validation Loss: 0.0739\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0565, Accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                              \n",
      "Training Loss: 0.1952\n",
      "Validation Loss: 0.1514\n",
      "--------------------\n",
      "Epoch 2/20                              \n",
      "Training Loss: 0.1021\n",
      "Validation Loss: 0.0964\n",
      "--------------------\n",
      "Epoch 3/20                              \n",
      "Training Loss: 0.0532\n",
      "Validation Loss: 0.0833\n",
      "--------------------\n",
      "Epoch 4/20                              \n",
      "Training Loss: 0.0372\n",
      "Validation Loss: 0.0711\n",
      "--------------------\n",
      "Epoch 5/20                              \n",
      "Training Loss: 0.0276\n",
      "Validation Loss: 0.0668\n",
      "--------------------\n",
      "Epoch 6/20                              \n",
      "Training Loss: 0.0209\n",
      "Validation Loss: 0.0655\n",
      "--------------------\n",
      "Epoch 7/20                              \n",
      "Training Loss: 0.0161\n",
      "Validation Loss: 0.0652\n",
      "--------------------\n",
      "Epoch 8/20                              \n",
      "Training Loss: 0.0125\n",
      "Validation Loss: 0.0655\n",
      "--------------------\n",
      "Epoch 9/20                              \n",
      "Training Loss: 0.0101\n",
      "Validation Loss: 0.0656\n",
      "--------------------\n",
      "Epoch 10/20                              \n",
      "Training Loss: 0.0081\n",
      "Validation Loss: 0.0658\n",
      "--------------------\n",
      "Epoch 11/20                              \n",
      "Training Loss: 0.0064\n",
      "Validation Loss: 0.0656\n",
      "--------------------\n",
      "Epoch 12/20                              \n",
      "Training Loss: 0.0052\n",
      "Validation Loss: 0.0653\n",
      "--------------------\n",
      "Epoch 13/20                              \n",
      "Training Loss: 0.0043\n",
      "Validation Loss: 0.0652\n",
      "--------------------\n",
      "Epoch 14/20                              \n",
      "Training Loss: 0.0037\n",
      "Validation Loss: 0.0654\n",
      "--------------------\n",
      "Epoch 15/20                              \n",
      "Training Loss: 0.0033\n",
      "Validation Loss: 0.0658\n",
      "--------------------\n",
      "Epoch 16/20                              \n",
      "Training Loss: 0.0029\n",
      "Validation Loss: 0.0661\n",
      "--------------------\n",
      "Epoch 17/20                              \n",
      "Training Loss: 0.0026\n",
      "Validation Loss: 0.0664\n",
      "--------------------\n",
      "Epoch 18/20                              \n",
      "Training Loss: 0.0023\n",
      "Validation Loss: 0.0668\n",
      "--------------------\n",
      "Epoch 19/20                              \n",
      "Training Loss: 0.0021\n",
      "Validation Loss: 0.0670\n",
      "--------------------\n",
      "Epoch 20/20                              \n",
      "Training Loss: 0.0019\n",
      "Validation Loss: 0.0673\n",
      "--------------------\n",
      "[####################] 100.00%"
     ]
    }
   ],
   "source": [
    "model = FFNN([\n",
    "    Dense(neuron_size=256, activation=\"relu\", kernel_initializer=\"he_normal\", input_size=784),\n",
    "    Dense(neuron_size=10, activation=\"softmax\", kernel_initializer=\"he_normal\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=True, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0594, Accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
